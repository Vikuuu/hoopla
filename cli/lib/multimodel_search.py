from PIL import Image
from sentence_transformers import SentenceTransformer


class MultiModel:
    def __init__(self, model_name="clip-ViT-B-32"):
        self.model = SentenceTransformer(model_name)

    def embed_image(self, image_path: str):
        image_data = Image.open(image_path)
        return self.model.encode(image_data)


def verify_image_embedding(image_path: str):
    multi_model = MultiModel()
    embedding = multi_model.embed_image(image_path)
    print(f"Embedding shape: {embedding.shape[0]} dimensions")
